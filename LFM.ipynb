{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read Movielens data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "def loadMovieLens(path='data/movielens'):\n",
    "  # Get movie titles\n",
    "  movies={}\n",
    "  # ingnore\n",
    "  for line in open(path+'/u.item',errors='ignore'):\n",
    "    (id,title)=line.split('|')[0:2]\n",
    "    movies[id]=title\n",
    "  \n",
    "  # Load data\n",
    "  prefs=defaultdict(dict)\n",
    "  for line in open(path+'/u.data'):\n",
    "    (user,movieid,rating,ts)=line.split('\\t')\n",
    "    prefs[int(user)][int(movieid)]=float(rating)\n",
    "  return prefs,movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop rows that has to much NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1    2    3    4    5    6    7    8    9    10  ...   934  935  936  \\\n",
      "1     5.0  4.0  NaN  NaN  4.0  4.0  NaN  NaN  NaN  4.0 ...   2.0  3.0  4.0   \n",
      "2     3.0  NaN  NaN  NaN  3.0  NaN  NaN  NaN  NaN  NaN ...   4.0  NaN  NaN   \n",
      "3     4.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  4.0   \n",
      "4     3.0  NaN  NaN  NaN  NaN  NaN  5.0  NaN  NaN  4.0 ...   5.0  NaN  NaN   \n",
      "5     3.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
      "6     5.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  5.0  NaN ...   NaN  NaN  5.0   \n",
      "7     4.0  NaN  NaN  NaN  NaN  2.0  5.0  3.0  4.0  4.0 ...   NaN  NaN  4.0   \n",
      "8     1.0  NaN  NaN  NaN  NaN  4.0  5.0  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
      "9     5.0  NaN  NaN  NaN  NaN  4.0  5.0  NaN  NaN  4.0 ...   NaN  1.0  4.0   \n",
      "10    3.0  2.0  NaN  NaN  NaN  NaN  4.0  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
      "11    2.0  NaN  NaN  4.0  NaN  NaN  3.0  3.0  NaN  4.0 ...   NaN  NaN  NaN   \n",
      "12    5.0  NaN  NaN  NaN  NaN  4.0  5.0  NaN  NaN  5.0 ...   NaN  NaN  NaN   \n",
      "13    5.0  4.0  NaN  NaN  NaN  2.0  NaN  NaN  NaN  3.0 ...   5.0  NaN  4.0   \n",
      "14    5.0  4.0  NaN  NaN  NaN  5.0  NaN  NaN  NaN  NaN ...   NaN  NaN  4.0   \n",
      "15    5.0  NaN  NaN  NaN  NaN  3.0  NaN  NaN  NaN  NaN ...   NaN  5.0  NaN   \n",
      "16    5.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  4.0 ...   NaN  NaN  4.0   \n",
      "17    3.0  NaN  NaN  NaN  4.0  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
      "18    4.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
      "19    5.0  3.0  NaN  NaN  NaN  4.0  NaN  NaN  NaN  NaN ...   NaN  NaN  5.0   \n",
      "20    4.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  5.0   \n",
      "21    1.0  NaN  NaN  NaN  3.0  3.0  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
      "22    4.0  NaN  NaN  NaN  NaN  3.0  5.0  5.0  NaN  5.0 ...   NaN  NaN  NaN   \n",
      "23    4.0  NaN  NaN  NaN  NaN  4.0  3.0  NaN  NaN  5.0 ...   NaN  NaN  NaN   \n",
      "24    3.0  NaN  NaN  NaN  4.0  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  4.0   \n",
      "25    4.0  4.0  NaN  NaN  3.0  NaN  3.0  NaN  NaN  NaN ...   4.0  NaN  4.0   \n",
      "26    3.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
      "27    2.0  NaN  NaN  NaN  NaN  NaN  4.0  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
      "28    4.0  NaN  NaN  NaN  NaN  2.0  5.0  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
      "29    1.0  NaN  NaN  NaN  4.0  NaN  3.0  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
      "30    3.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
      "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ... ...   ...  ...  ...   \n",
      "1653  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
      "1654  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
      "1655  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
      "1656  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
      "1657  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
      "1658  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
      "1659  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
      "1660  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
      "1661  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
      "1662  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
      "1663  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
      "1664  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
      "1665  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
      "1666  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
      "1667  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
      "1668  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
      "1669  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
      "1670  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
      "1671  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
      "1672  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
      "1673  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
      "1674  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
      "1675  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
      "1676  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
      "1677  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
      "1678  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
      "1679  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
      "1680  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
      "1681  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
      "1682  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
      "\n",
      "      937  938  939  940  941  942  943  \n",
      "1     NaN  4.0  NaN  NaN  5.0  NaN  NaN  \n",
      "2     NaN  NaN  NaN  NaN  NaN  NaN  5.0  \n",
      "3     NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "4     NaN  NaN  NaN  2.0  NaN  NaN  NaN  \n",
      "5     NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "6     NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "7     NaN  4.0  NaN  4.0  4.0  NaN  NaN  \n",
      "8     NaN  NaN  NaN  5.0  NaN  NaN  NaN  \n",
      "9     5.0  3.0  5.0  3.0  NaN  NaN  3.0  \n",
      "10    NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "11    NaN  NaN  NaN  NaN  NaN  NaN  4.0  \n",
      "12    NaN  NaN  NaN  4.0  NaN  NaN  5.0  \n",
      "13    NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "14    4.0  NaN  NaN  3.0  NaN  NaN  NaN  \n",
      "15    NaN  2.0  5.0  NaN  4.0  NaN  NaN  \n",
      "16    NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "17    NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "18    NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "19    1.0  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "20    NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "21    NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "22    NaN  NaN  NaN  NaN  NaN  NaN  4.0  \n",
      "23    NaN  NaN  NaN  NaN  NaN  NaN  4.0  \n",
      "24    NaN  NaN  NaN  NaN  NaN  NaN  4.0  \n",
      "25    NaN  4.0  NaN  NaN  NaN  NaN  NaN  \n",
      "26    NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "27    NaN  NaN  NaN  NaN  NaN  NaN  4.0  \n",
      "28    NaN  NaN  NaN  NaN  NaN  NaN  4.0  \n",
      "29    NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "30    NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "...   ...  ...  ...  ...  ...  ...  ...  \n",
      "1653  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1654  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1655  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1656  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1657  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1658  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1659  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1660  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1661  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1662  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1663  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1664  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1665  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1666  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1667  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1668  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1669  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1670  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1671  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1672  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1673  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1674  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1675  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1676  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1677  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1678  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1679  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1680  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1681  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1682  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "\n",
      "[1682 rows x 943 columns]\n",
      "334\n"
     ]
    }
   ],
   "source": [
    "# data = DataFrame(movies,index=[0])\n",
    "# data\n",
    "prefs,movies = loadMovieLens()\n",
    "data = DataFrame(prefs)\n",
    "print(data)\n",
    "counts=[n for n in range(1,1682) if data.ix[n].count()>100]\n",
    "print(len(counts))\n",
    "cleanedData = data.ix[counts]\n",
    "cleanedData=cleanedData.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### svd test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "955621.0\n",
      "0: 0.000000\n",
      "20: 0.621745\n",
      "40: 0.692749\n",
      "60: 0.747882\n",
      "80: 0.792778\n",
      "100: 0.830471\n",
      "120: 0.862321\n",
      "140: 0.889204\n",
      "160: 0.912028\n",
      "180: 0.931400\n",
      "200: 0.947672\n",
      "220: 0.961278\n",
      "240: 0.972500\n",
      "260: 0.981599\n",
      "280: 0.988843\n",
      "300: 0.994392\n",
      "320: 0.998309\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "U,Sigma,VT=np.linalg.svd(cleanedData)\n",
    "Squ=[value**2 for value in Sigma]\n",
    "valueSum = sum(Squ)\n",
    "print(valueSum)\n",
    "for n in range(0,len(Sigma)+1,20):\n",
    "    print(\"%d: %f\" % (n,sum(Squ[:n])/valueSum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LFM test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def LFM(user_items, F, N, alpha=0.02, lam=0.01):\n",
    "    P,Q = InitModel(user_items, F)\n",
    "    print(P.shape)\n",
    "    print(Q.shape)\n",
    "    user_num, item_num = user_items.shape\n",
    "    for step in range(N):\n",
    "        total_error = 0.0\n",
    "        for u in range(user_num):\n",
    "            for i in range(item_num):\n",
    "                err = user_items[u][i]-np.dot(P[u],Q[i])\n",
    "                total_error += err**2\n",
    "                gp = err*Q[i]+lam*P[u]\n",
    "                gq = err*P[u]+lam*Q[i]\n",
    "                P[u] += alpha*gp\n",
    "                Q[i] += alpha*gq        \n",
    "        print(\"step %d: %f\"%(step,total_error))\n",
    "    return P,Q\n",
    "                    \n",
    "def InitModel(user_items, F):\n",
    "    user_num, item_num = user_items.shape\n",
    "    #归一化\n",
    "    P = np.random.rand(user_num,F)/math.sqrt(F)\n",
    "    Q = np.random.rand(item_num,F)/math.sqrt(F)\n",
    "    return P,Q\n",
    "\n",
    "def Recommend(user, P, Q):\n",
    "    rank = dict()\n",
    "    for f, puf in P[user].items():\n",
    "        for i, qfi in Q[f].items():\n",
    "            if i not in rank:\n",
    "                rank[i] += puf*qfi\n",
    "    return rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(334, 100)\n",
      "(943, 100)\n",
      "step 0: 584337.583726\n",
      "step 1: 490191.278921\n",
      "step 2: 418864.012668\n",
      "step 3: 358881.901395\n",
      "step 4: 321618.951172\n",
      "step 5: 310418.634103\n",
      "step 6: 306510.812212\n",
      "step 7: 303417.442156\n",
      "step 8: 301803.642731\n",
      "step 9: 301413.912038\n",
      "step 10: 301827.688231\n",
      "step 11: 302747.147785\n",
      "step 12: 303973.375980\n",
      "step 13: 305398.626397\n",
      "step 14: 306872.829500\n",
      "step 15: 308393.424479\n",
      "step 16: 311826.061934\n",
      "step 17: 348221.975988\n",
      "step 18: 416902.277428\n",
      "step 19: 545567.512213\n",
      "step 20: 524578.036288\n",
      "step 21: 442045.588550\n",
      "step 22: 396997.031676\n",
      "step 23: 376903.086617\n",
      "step 24: 365042.757329\n",
      "step 25: 357016.699922\n",
      "step 26: 350958.211261\n",
      "step 27: 346321.247024\n",
      "step 28: 342829.326506\n",
      "step 29: 340029.759324\n",
      "step 30: 337758.409284\n",
      "step 31: 335799.030269\n",
      "step 32: 334216.789684\n",
      "step 33: 332877.120638\n",
      "step 34: 331899.110075\n",
      "step 35: 331735.247804\n",
      "step 36: 339832.081594\n",
      "step 37: 348969.708274\n",
      "step 38: 361326.054613\n",
      "step 39: 381049.640604\n",
      "step 40: 375102.573256\n",
      "step 41: 364623.979324\n",
      "step 42: 352931.521536\n",
      "step 43: 343612.312161\n",
      "step 44: 338210.733003\n",
      "step 45: 335507.290295\n",
      "step 46: 334706.315342\n",
      "step 47: 335561.118211\n",
      "step 48: 337662.374113\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-254-a5aa82ec5f44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleanedData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLFM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-253-50ca72185bba>\u001b[0m in \u001b[0;36mLFM\u001b[0;34m(user_items, F, N, alpha, lam)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mtotal_error\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mgp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0mgq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0mP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mQ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "arr = np.array(cleanedData)\n",
    "P,Q = LFM(arr,100,1000)\n",
    "print(P)\n",
    "print(Q)\n",
    "print(np.dot(P,Q.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 3)\n",
      "(4, 3)\n",
      "step 0: 315.916934\n",
      "step 1: 275.978519\n",
      "step 2: 220.798179\n",
      "step 3: 159.324154\n",
      "step 4: 108.119942\n",
      "step 5: 77.506033\n",
      "step 6: 64.059623\n",
      "step 7: 59.247409\n",
      "step 8: 57.550914\n",
      "step 9: 56.798797\n",
      "step 10: 56.321052\n",
      "step 11: 55.921708\n",
      "step 12: 55.535920\n",
      "step 13: 55.135737\n",
      "step 14: 54.704792\n",
      "step 15: 54.230633\n",
      "step 16: 53.701785\n",
      "step 17: 53.106249\n",
      "step 18: 52.430523\n",
      "step 19: 51.658811\n",
      "step 20: 50.772343\n",
      "step 21: 49.748806\n",
      "step 22: 48.561987\n",
      "step 23: 47.181824\n",
      "step 24: 45.575145\n",
      "step 25: 43.707501\n",
      "step 26: 41.546534\n",
      "step 27: 39.067262\n",
      "step 28: 36.259338\n",
      "step 29: 33.135713\n",
      "step 30: 29.741041\n",
      "step 31: 26.157059\n",
      "step 32: 22.501436\n",
      "step 33: 18.917414\n",
      "step 34: 15.554236\n",
      "step 35: 12.542556\n",
      "step 36: 9.972335\n",
      "step 37: 7.880780\n",
      "step 38: 6.253849\n",
      "step 39: 5.039088\n",
      "step 40: 4.163568\n",
      "step 41: 3.550446\n",
      "step 42: 3.130299\n",
      "step 43: 2.846557\n",
      "step 44: 2.656420\n",
      "step 45: 2.529215\n",
      "step 46: 2.443802\n",
      "step 47: 2.386000\n",
      "step 48: 2.346458\n",
      "step 49: 2.319065\n",
      "step 50: 2.299831\n",
      "step 51: 2.286146\n",
      "step 52: 2.276286\n",
      "step 53: 2.269099\n",
      "step 54: 2.263807\n",
      "step 55: 2.259875\n",
      "step 56: 2.256929\n",
      "step 57: 2.254707\n",
      "step 58: 2.253020\n",
      "step 59: 2.251731\n",
      "step 60: 2.250742\n",
      "step 61: 2.249978\n",
      "step 62: 2.249386\n",
      "step 63: 2.248924\n",
      "step 64: 2.248562\n",
      "step 65: 2.248278\n",
      "step 66: 2.248054\n",
      "step 67: 2.247876\n",
      "step 68: 2.247736\n",
      "step 69: 2.247624\n",
      "step 70: 2.247536\n",
      "step 71: 2.247466\n",
      "step 72: 2.247412\n",
      "step 73: 2.247371\n",
      "step 74: 2.247339\n",
      "step 75: 2.247317\n",
      "step 76: 2.247302\n",
      "step 77: 2.247293\n",
      "step 78: 2.247290\n",
      "step 79: 2.247291\n",
      "step 80: 2.247297\n",
      "step 81: 2.247306\n",
      "step 82: 2.247318\n",
      "step 83: 2.247334\n",
      "step 84: 2.247351\n",
      "step 85: 2.247371\n",
      "step 86: 2.247393\n",
      "step 87: 2.247416\n",
      "step 88: 2.247442\n",
      "step 89: 2.247468\n",
      "step 90: 2.247496\n",
      "step 91: 2.247525\n",
      "step 92: 2.247554\n",
      "step 93: 2.247585\n",
      "step 94: 2.247616\n",
      "step 95: 2.247648\n",
      "step 96: 2.247680\n",
      "step 97: 2.247713\n",
      "step 98: 2.247746\n",
      "step 99: 2.247780\n",
      "[[ 0.20785918  1.25020371  1.94531063]\n",
      " [ 1.95350717 -0.32798824  1.03893401]\n",
      " [-0.11307323  1.129728    1.18801681]\n",
      " [ 1.44442724  0.97532588 -1.04404556]\n",
      " [ 1.33476995  1.42597379  0.93299021]\n",
      " [ 1.55840184  1.56631535  0.68561349]]\n",
      "[[ 1.52066994  0.51648985  2.2497404 ]\n",
      " [-0.32324065  2.16899476  1.33806324]\n",
      " [ 2.24907208  1.19609775 -0.87631072]\n",
      " [ 1.55912947  1.42692018  1.20513521]]\n",
      "[[ 5.33824665  5.24744539  0.25815956  4.4523826 ]\n",
      " [ 5.13856884  0.0473017   3.09084344  3.8298135 ]\n",
      " [ 3.08427539  4.07656559  0.0558834   2.86745675]\n",
      " [ 0.35141152  0.25158014  5.33011441  2.38554519]\n",
      " [ 4.8652313   3.90987769  3.89000854  5.24020929]\n",
      " [ 4.72125318  3.81098518  4.7776139   5.49101417]]\n"
     ]
    }
   ],
   "source": [
    "mat = [[5,5,0,5],[5,0,3,4],[3,4,0,3],[0,0,5,3],[5,4,4,5],[5,4,5,5]]\n",
    "arr = np.array(mat)\n",
    "P,Q = LFM(arr,3,100)\n",
    "print(P)\n",
    "print(Q)\n",
    "print(np.dot(P,Q.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
